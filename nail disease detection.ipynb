{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd4d8b8-898d-4cba-b81a-5eb33e9d6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_8332\\2922682764.py\", line 3, in <module>\n",
      "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py\", line 468, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\__init__.py\", line 2, in <module>\n",
      "    from keras.api import DTypePolicy\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\__init__.py\", line 8, in <module>\n",
      "    from keras.api import activations\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\activations\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.activations import deserialize\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\__init__.py\", line 13, in <module>\n",
      "    from keras.src import visualization\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\visualization\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.visualization import draw_bounding_boxes\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\visualization\\draw_bounding_boxes.py\", line 11, in <module>\n",
      "    import cv2\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py\", line 181, in <module>\n",
      "    bootstrap()\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py\", line 153, in bootstrap\n",
      "    native_module = importlib.import_module(\"cv2\")\n",
      "  File \"C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d44b483-6db0-40e3-8406-30a4ea5bd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_dir = 'C:\\\\Users\\\\varsh\\\\Downloads\\\\archive (3)\\\\data\\\\train'\n",
    "val_dir = 'C:\\\\Users\\\\varsh\\\\Downloads\\\\archive (3)\\\\data\\\\validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e712b9d9-e509-48ea-8096-c2a48819e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels from folder names\n",
    "class_labels = sorted(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c4717e-7553-4970-acf6-59e5d2fb5b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training data: {'Acral_Lentiginous_Melanoma': 735, 'Healthy_Nail': 323, 'Onychogryphosis': 677, 'blue_finger': 603, 'clubbing': 767, 'pitting': 639}\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in your training dataset\n",
    "class_counts = {class_label: 0 for class_label in class_labels}\n",
    "\n",
    "for class_label in class_labels:\n",
    "    class_counts[class_label] = len(os.listdir(os.path.join(train_dir, class_label)))\n",
    "\n",
    "print(f\"Class distribution in training data: {class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e939235b-3fbb-44ef-a9a0-203382578901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size & batch\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c4ab57-a912-46c4-97de-cb6f0e4f12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3744 images belonging to 6 classes.\n",
      "Found 91 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5680c038-6b22-4489-9fb2-ac5f351e073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 without top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze it initially\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(len(class_labels), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0e3705-a83f-4025-ae0b-3ff216dad608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last 10 layers of MobileNetV2\n",
    "for layer in base_model.layers[-10:]:  # You can adjust the number of layers you want to unfreeze\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again after unfreezing layers\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349aaa2e-8695-4c70-b17f-b007c226e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c0d0ea-ea7a-4fac-af95-7e54c7236eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class weights\n",
    "class_weights = {\n",
    "    0: 1.0,  # Acral_Lentiginous_Melanoma\n",
    "    1: 1.5,  # Healthy_Nail (lowest number of samples, give it a higher weight)\n",
    "    2: 1.0,  # Onychogryphosis\n",
    "    3: 1.0,  # blue_finger\n",
    "    4: 1.0,  # clubbing\n",
    "    5: 1.2   # pitting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48aeecc2-d1c1-41f8-bec3-2634e4d7b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.2898 - loss: 1.7907 - val_accuracy: 0.2967 - val_loss: 1.5904\n",
      "Epoch 2/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 1s/step - accuracy: 0.5715 - loss: 1.2728 - val_accuracy: 0.3626 - val_loss: 1.4284\n",
      "Epoch 3/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.6588 - loss: 1.0425 - val_accuracy: 0.4176 - val_loss: 1.2769\n",
      "Epoch 4/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.7066 - loss: 0.9132 - val_accuracy: 0.5055 - val_loss: 1.1146\n",
      "Epoch 5/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.7007 - loss: 0.8502 - val_accuracy: 0.6154 - val_loss: 0.9668\n",
      "Epoch 6/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7394 - loss: 0.7554 - val_accuracy: 0.6923 - val_loss: 0.8527\n",
      "Epoch 7/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.7380 - loss: 0.7596 - val_accuracy: 0.7363 - val_loss: 0.7648\n",
      "Epoch 8/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.7655 - loss: 0.6886 - val_accuracy: 0.7692 - val_loss: 0.6957\n",
      "Epoch 9/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.7627 - loss: 0.6526 - val_accuracy: 0.7802 - val_loss: 0.6454\n",
      "Epoch 10/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.7730 - loss: 0.6420 - val_accuracy: 0.8132 - val_loss: 0.5636\n",
      "Epoch 11/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - accuracy: 0.7913 - loss: 0.6248 - val_accuracy: 0.8242 - val_loss: 0.5326\n",
      "Epoch 12/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.7874 - loss: 0.6066 - val_accuracy: 0.8132 - val_loss: 0.5161\n",
      "Epoch 13/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.7888 - loss: 0.5834 - val_accuracy: 0.8132 - val_loss: 0.5031\n",
      "Epoch 14/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.8088 - loss: 0.5635 - val_accuracy: 0.8352 - val_loss: 0.4754\n",
      "Epoch 15/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8118 - loss: 0.5515 - val_accuracy: 0.8571 - val_loss: 0.4466\n",
      "Epoch 16/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8048 - loss: 0.5503 - val_accuracy: 0.8681 - val_loss: 0.4331\n",
      "Epoch 17/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.8281 - loss: 0.5138 - val_accuracy: 0.8681 - val_loss: 0.4286\n",
      "Epoch 18/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8282 - loss: 0.5299 - val_accuracy: 0.8791 - val_loss: 0.4062\n",
      "Epoch 19/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.8199 - loss: 0.5107 - val_accuracy: 0.8791 - val_loss: 0.3735\n",
      "Epoch 20/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.8423 - loss: 0.4726 - val_accuracy: 0.8791 - val_loss: 0.3671\n",
      "Epoch 21/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.8418 - loss: 0.4701 - val_accuracy: 0.8791 - val_loss: 0.3697\n",
      "Epoch 22/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.8511 - loss: 0.4733 - val_accuracy: 0.8791 - val_loss: 0.3654\n",
      "Epoch 23/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1s/step - accuracy: 0.8471 - loss: 0.4481 - val_accuracy: 0.8901 - val_loss: 0.3519\n",
      "Epoch 24/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.8539 - loss: 0.4460 - val_accuracy: 0.8901 - val_loss: 0.3446\n",
      "Epoch 25/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - accuracy: 0.8600 - loss: 0.4275 - val_accuracy: 0.9011 - val_loss: 0.3435\n",
      "Epoch 26/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8415 - loss: 0.4408 - val_accuracy: 0.9011 - val_loss: 0.3399\n",
      "Epoch 27/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.8529 - loss: 0.4324 - val_accuracy: 0.9011 - val_loss: 0.3452\n",
      "Epoch 28/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 1s/step - accuracy: 0.8724 - loss: 0.3945 - val_accuracy: 0.8901 - val_loss: 0.3609\n",
      "Epoch 29/50\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.8617 - loss: 0.4129 - val_accuracy: 0.8901 - val_loss: 0.3684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c01bd4a710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b18c11e-13c4-41f8-9f01-6905fd8fd616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step\n",
      "\n",
      "✅ Validation Accuracy: 90.11%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_data.reset()\n",
    "y_pred = np.argmax(model.predict(val_data), axis=1)\n",
    "y_true = val_data.classes[:len(y_pred)]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603393e8-e2b9-4de2-9168-eecad4bf9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"naildisease_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "019ce8f0-dd8b-4d11-9675-dd377ae6b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "# Step 7: Related systemic conditions mapping\n",
    "nail_to_systemic_map = {\n",
    "    'onycholysis': ['Thyroid disorders', 'Iron-deficiency anemia', 'Psoriasis'],\n",
    "    'melanonychia': ['Melanoma', 'HIV', 'Laugier–Hunziker syndrome'],\n",
    "    'pitting': ['Heart disease', 'Lung cancer', 'Inflammatory bowel disease'],\n",
    "    'koilonychia': ['Iron-deficiency anemia', 'Celiac disease', 'Heart disease'],\n",
    "    'leukonychia': ['Liver cirrhosis', 'Kidney failure', 'Zinc deficiency'],\n",
    "    'beau_lines': ['Diabetes', 'High fever', 'Chemotherapy side effects'],\n",
    "    'yellow_nail_syndrome': ['Respiratory diseases', 'Lymphedema'],\n",
    "    'muehrcke_lines': ['Hypoalbuminemia', 'Kidney disease'],\n",
    "    'clubbing': ['Psoriasis', 'Alopecia areata'],\n",
    "    'healthy': ['No associated systemic disease']\n",
    "}\n",
    "\n",
    "# Step 8: Predictor Function\n",
    "def predict_nail_disease(img_path):\n",
    "    model = load_model(\"naildisease_model.h5\")\n",
    "\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_class = class_labels[predicted_index]\n",
    "   \n",
    "    # Show the image\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {predicted_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n🔍 Predicted Nail Condition: {predicted_class}\")\n",
    "    print(\"🩺 Possible Related Health Conditions:\")\n",
    "    for disease in nail_to_systemic_map.get(predicted_class, [\"No associated condition found.\"]):\n",
    "        print(f\" - {disease}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2070d86-f83c-419f-9e96-5f66c96f683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Example usage\n",
    "# Replace with your own image path\n",
    "predict_nail_disease(\"025.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2300450-edca-4a2e-805c-ed8d833f18fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
